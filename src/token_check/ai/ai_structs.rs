use serde::{Deserialize, Serialize};
use std::fmt;

use crate::token_check::{
    deepseek::structs::AssistantMessageDeepSeek, openai::structs::AssistantMessage,
};

/// This module defines various structures used for communicating with an AI chat API.
/// It includes:
/// - Enums to represent different prompt types.
/// - Request structures for sending a chat completion request.
/// - Response structures for handling the API response.
/// - Error response structures for error handling.
/// - A helper trait (`HasContent`) to extract the content from assistant messages.

/// Enum representing the type of prompt to send to the AI.
#[derive(Clone, Debug, PartialEq, Eq, Default)]
pub enum PromptType {
    /// Prompt based on website content.
    Website,
    /// Prompt based on code content (default).
    #[default]
    Code,
    /// A prompt requesting a full review with comprehensive analysis.
    FullReview,
}

impl fmt::Display for PromptType {
    /// Converts the `PromptType` into a corresponding string understood by the API.
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let as_str = match self {
            PromptType::Website => "website_content",
            PromptType::Code => "code_content",
            PromptType::FullReview => "all_analysis_to_review",
        };
        // Write the mapped string value into the formatter.
        write!(f, "{}", as_str)
    }
}

/// ---------------------
///   Request Structures
/// ---------------------

/// Represents a request to the AI chat completion API.
///
/// This struct mirrors the expected JSON payload when initiating a chat completion
/// request to the AI service.
#[derive(Serialize)]
pub struct ChatCompletionRequest {
    /// The model name (e.g. "gpt-3.5-turbo", "gpt-4").
    pub model: String,
    /// The sequence of messages forming the conversation.
    pub messages: Vec<MessageToSend>,
    /// Sampling temperature to control randomness.
    pub temperature: f64,
    /// Maximum tokens to generate in the response.
    pub max_tokens: usize,
    /// The cumulative probability at which to cut off sampling.
    pub top_p: f64,
}

/// Represents a single message in the conversation sent to the AI model.
///
/// The message includes the role of the sender (system, user, or assistant)
/// and its content.
#[derive(Serialize)]
pub struct MessageToSend {
    /// The role of the sender.
    pub role: String,
    /// The content of the message.
    pub content: String,
}

/// ---------------------
///   Response Structures
/// ---------------------

/// Represents the entire chat completion response returned by the AI API.
///
/// Generic parameters allow flexibility in the type of message contained in the choices
/// and in representing the usage information.
#[derive(Debug, Deserialize)]
pub struct AiChatCompletion<T, K> {
    /// Unique identifier for the response.
    #[serde(rename = "id")]
    _id: String,
    /// Type descriptor for the response object.
    #[serde(rename = "object")]
    _object: String,
    /// Timestamp (in seconds) when the response was created.
    #[serde(rename = "created")]
    _created: i64,
    /// The model used to generate the response.
    #[serde(rename = "model")]
    _model: String,
    /// List of individual choices provided by the AI.
    #[serde(rename = "choices")]
    pub choices: Vec<Choice<T>>,
    /// Additional information regarding resource usage (e.g., token counts).
    #[serde(default, rename = "usage")]
    _usage: K,
    /// Optional system fingerprint useful for tracking.
    #[serde(default, rename = "system_fingerprint")]
    _system_fingerprint: Option<String>,
}

/// Represents an individual choice (or completion) from the AI response.
///
/// Each choice typically contains an assistant message and related metadata.
#[derive(Debug, Deserialize)]
pub struct Choice<T> {
    /// The index of this choice in the list.
    #[serde(rename = "index")]
    _index: i64,
    /// The message generated by the AI for this choice.
    pub message: T,
    /// Optionally, the log probabilities of the tokens (if requested).
    #[serde(default)]
    #[serde(rename = "logprobs")]
    _logprobs: Option<()>,
    /// Reason for why the generation finished (if available).
    #[serde(default)]
    #[serde(rename = "finish_reason")]
    _finish_reason: Option<String>,
}

/// Represents a token check for code content.
///
/// The expected JSON payload contains information that assesses whether the code
/// might be a scam, along with reasons and legitimacy details.
#[derive(Deserialize, Clone, Debug)]
pub struct TokenCodeCheck {
    /// Indicates if the code might be a scam.
    pub possible_scam: bool,
    /// Explanation for the scam assessment.
    pub reason: String,
    /// Indicates if the code could legitimately justify suspicious code patterns.
    pub could_legitimately_justify_suspicious_code: bool,
    /// Additional reasoning regarding legitimacy of the code.
    pub reason_could_be_legitimate_or_not: String,
}

/// Represents a token check for website content.
///
/// Contains indicators and summarizing information for assessing potential scams on a website.
#[derive(Deserialize, Clone, Debug, Default)]
pub struct TokenWebsiteCheck {
    /// Indicates if the website might be a scam.
    pub possible_scam: bool,
    /// Explanation for the scam assessment.
    pub reason: String,
    /// A summary of the overall assessment.
    pub summary: String,
}

// /// Represents a final assessment for a token check on content.
// #[derive(Deserialize, Clone, Debug)]
// pub struct TokenFinalAssessment {
//     /// The final scam assessment value.
//     pub final_scam_assessment: bool,
//     /// Reasoning for the final assessment.
//     pub reason: String,
//     /// Indicates if the content could legitimately justify suspicious aspects.
//     pub could_legitimately_justify_suspicious_code: bool,
// }

/// ---------------------
///   Error Response Structures
/// ---------------------

/// Represents an error response from the AI API.
///
/// This structure encapsulates detailed error information returned if the API request fails.
#[derive(Deserialize, Debug)]
pub struct AiErrorResponse {
    /// Detailed error information.
    pub error: AiErrorDetail,
}

/// Provides detailed error information encountered during an API request.
#[derive(Deserialize, Debug)]
pub struct AiErrorDetail {
    /// The error message describing the failure.
    pub message: String,
    /// Optional identifier for the type of error.
    #[serde(default)]
    pub r#type: Option<String>,
    /// Optional error code.
    #[serde(default)]
    pub code: Option<String>,
}

/// ---------------------
///   Traits and Implementations
/// ---------------------

/// A trait for extracting content from various assistant message types.
///
/// This trait defines a common interface to retrieve textual content from a message,
/// accommodating different underlying structures.
pub trait HasContent {
    /// Returns the content of the message, if available.
    fn get_content(&self) -> Option<String>;
}

impl HasContent for AssistantMessage {
    /// Retrieves the content from an `AssistantMessage`.
    ///
    /// The content is returned as an owned `String` if it exists.
    fn get_content(&self) -> Option<String> {
        // Since `content` is a String, cloning is required to return an owned value.
        self.content.clone()
    }
}

impl HasContent for AssistantMessageDeepSeek {
    /// Retrieves the content from an `AssistantMessageDeepSeek`.
    ///
    /// Similar to `AssistantMessage`, this returns a cloned string if the content is present.
    fn get_content(&self) -> Option<String> {
        self.content.clone()
    }
}
